---
title: "assignment_4"
author: "Santhosh reddy Mallikireddy"
date: "03/05/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

#Loading the data
```{r}
library(tibble)
library(readr)
library(keras)
data <- read_csv("jena_climate_2009_2016.csv")
glimpse(data)


```


If we were trying to predict average temperature for the next month given a few month of past data, the problem would be easy, due to the reliable year-scale periodicity of the data. But looking at the data over a scale of days, the temperature looks a lot more chaotic. 

So our aim is to see if this data is predictable at a daily scale.

Since the dataset we have is huge we are taking only 20000 samples.
```{r}
data <- data.matrix(data[,-1])
```

#Data preprocessing
we preprocess the data by subtracting the mean of each timeseries and dividing by the standard deviation. we are going to use the first 20,000 timesteps as training data, so compute the mean and standard deviation for normalization only on this fraction of the data.
```{r}
train_data <- data[1:20000,]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
```


```{r}
generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 128, step = 6) {
  if (is.null(max_index))
    max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + length(rows)
    }
    
    samples <- array(0, dim = c(length(rows), 
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
                     
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]] - 1, 
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,2]
    }            
    
    list(samples, targets)
  }
}
```
The i variable contains the state that tracks next window of data to return, so it is updated using superassignment (e.g. i <<- i + length(rows)).

Now, let’s use the abstract generator function to instantiate three generators: one for training, one for validation, and one for testing. Each will look at different temporal segments of the original data: the training generator looks at the first 15000 timesteps, the validation generator looks at the following 2000, and the test generator looks at the remainder.

We will use the following parameter values:

lookback = 1440, i.e. our observations will go back 10 days.
steps = 6, i.e. our observations will be sampled at one data point per hour.
delay = 144, i.e. our targets will be 24 hours in the future
```{r}
lookback <- 1440
step <- 6 #The period, in timesteps, at which you sample data. You’ll set it 6 in order to draw one data point every hour.
delay <- 144
batch_size <- 128
train_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 15000,
  shuffle = TRUE,
  step = step, 
  batch_size = batch_size
)
val_gen = generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 15001,
  max_index = 17000,
  step = step,
  batch_size = batch_size
)
test_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 17001,
  max_index = 20000,
  step = step,
  batch_size = batch_size
)
# This is how many steps to draw from `val_gen`
# in order to see the whole validation set:
val_steps <- (17000 - 15001 - lookback) / batch_size
  # This is how many steps to draw from `test_gen`
# in order to see the whole test set:
test_steps <- (nrow(data) - 17001 - lookback) / batch_size
```

#Non Machine Learning Baseline

In our case, the temperature timeseries can safely be assumed to be continuous (the temperatures tomorrow are likely to be close to the temperatures today) as well as periodical with a daily period. Thus a common sense approach would be to always predict that the temperature 24 hours from now will be equal to the temperature right now. Let’s evaluate this approach, using the Mean Absolute Error metric (MAE). Mean Absolute Error is simply equal to:
```{r}
evaluate_naive_method <- function() {
  batch_maes <- c()
  for (step in 1:val_steps) {
    c(samples, targets) %<-% val_gen()
    preds <- samples[,dim(samples)[[2]],2]
    mae <- mean(abs(preds - targets))
    batch_maes <- c(batch_maes, mae)
  }
  print(mean(batch_maes))
}

evaluate_naive_method()
```
MAE values is 0.38 for this method. Which means base performance of our model is 0.38.
Since our temperature data has been normalized to be centered on 0 and have a standard deviation of one, this number is not immediately interpretable. That’s a fairly large average absolute error – now the game is to leverage our knowledge of deep learning to do better.



THE MODEL CHECKPOING AND EARLY STOPPING CALLBACKS:

You can use callback_early_stopping to interrupt training once a target metric being
monitored has stopped improving for a fixed number of epochs. For instance, this
callback allows you to interrupt training as soon as you start overfitting, thus avoiding
having to retrain your model for a smaller number of epochs. This callback is typically
used in combination with callback_model_checkpoint.
```{r}
model <- keras_model_sequential() %>% 
  layer_flatten(input_shape = c(lookback / step, dim(data)[-1])) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1)

callbacks_list <- list(
  callback_early_stopping(
    monitor = "acc",
    patience = 1
    ),
  callback_model_checkpoint(
    filepath = "my_model.h5",
    monitor = "val_loss",
    save_best_only = TRUE
    )
  )

model %>% compile(
  optimizer = optimizer_rmsprop(),
  loss = "mae",
  metrics = c("acc")
)

history <- model %>% fit_generator(
  train_gen,
  steps_per_epoch = 500,
  epochs = 10,
  callbacks = callbacks_list,
  validation_data = val_gen,
  validation_steps = val_steps
)
plot(history)
```

THE REDUCE LEARNING RATE ON PLATEAU CALLBACK:

You can use this callback to reduce the learning rate when the validation loss has stopped
improving. Reducing or increasing the learning rate in case of a loss plateau is is an
effective strategy to get out of local minima during training. The following uses
callback_reduce_lr_on_plateau:
```{r}
model <- keras_model_sequential() %>% 
  layer_flatten(input_shape = c(lookback / step, dim(data)[-1])) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1)

callbacks_list <- list(
  callback_reduce_lr_on_plateau(
    monitor = "val_loss",
    factor = 0.1,
    patience = 10
    )
  )

history <- model %>% fit_generator(
  train_gen,
  steps_per_epoch = 500,
  epochs = 10,
  callbacks = callbacks_list,
  validation_data = val_gen,
  validation_steps = val_steps
)
plot(history)
```

Training the model with a TensorBoard callback:
```{r}
#Creating a directory for TensorBoard log files
dir.create("my_log_dir")

model <- keras_model_sequential() %>% 
  layer_flatten(input_shape = c(lookback / step, dim(data)[-1])) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1)

tensorboard("my_log_dir")

callbacks = list(
  callback_tensorboard(
    log_dir = "my_log_dir",
    histogram_freq = 1,
    embeddings_freq = 1,
    )
)

history <- model %>% fit_generator(
  train_gen,
  steps_per_epoch = 500,
  epochs = 10,
  callbacks = callbacks,
  validation_data = val_gen,
  validation_steps = val_steps
)
plot(history)
```


Evaluating on the Test set
```{r}
history <- model %>% fit_generator(
  test_gen,
  steps_per_epoch = 50,
  epochs = 3,
  validation_steps = test_steps
)

```

```{r}
plot(history)
```

